{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f02fcd-a8d2-4344-8785-a9919761df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Checking File Existence ---\n",
      "SUCCESS: Both files found!\n",
      "\n",
      "--- Step 2: Peeking at the Data ---\n",
      "SUCCESS: Successfully read the first 5 rows of train_data.csv\n",
      "\n",
      "Here are the columns in your data:\n",
      "['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3']\n",
      "\n",
      "Here is the first row of data:\n",
      "customer_ID    0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...\n",
      "S_2                                                   2017-03-09\n",
      "P_2                                                     0.938469\n",
      "D_39                                                    0.001733\n",
      "B_1                                                     0.008724\n",
      "                                     ...                        \n",
      "D_141                                                   0.003818\n",
      "D_142                                                        NaN\n",
      "D_143                                                   0.000569\n",
      "D_144                                                    0.00061\n",
      "D_145                                                   0.002674\n",
      "Name: 0, Length: 190, dtype: object\n",
      "\n",
      "--- READY FOR NEXT STEP ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define filenames\n",
    "TRAIN_FILE = 'train_data.csv'\n",
    "LABEL_FILE = 'train_labels.csv'\n",
    "\n",
    "print(\"--- Step 1: Checking File Existence ---\")\n",
    "# Check if files exist in the current folder\n",
    "if os.path.exists(TRAIN_FILE) and os.path.exists(LABEL_FILE):\n",
    "    print(\"SUCCESS: Both files found!\")\n",
    "else:\n",
    "    print(\"ERROR: One or more files are missing. Please check your folder.\")\n",
    "    print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "    # Stop here if files are missing\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- Step 2: Peeking at the Data ---\")\n",
    "try:\n",
    "    # Read only the first 5 rows to ensure it works\n",
    "    # This avoids crashing your memory\n",
    "    df_preview = pd.read_csv(TRAIN_FILE, nrows=5)\n",
    "    print(\"SUCCESS: Successfully read the first 5 rows of train_data.csv\")\n",
    "    \n",
    "    print(\"\\nHere are the columns in your data:\")\n",
    "    print(df_preview.columns.tolist()[:10]) # Print first 10 columns only\n",
    "    \n",
    "    print(\"\\nHere is the first row of data:\")\n",
    "    print(df_preview.iloc[0])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Could not read the CSV file. Reason: {e}\")\n",
    "\n",
    "print(\"\\n--- READY FOR NEXT STEP ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd4f3d0-fe83-4997-b846-855cb346dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Big Data Pipeline ---\n",
      "Loading labels...\n",
      "Labels loaded: 458913 rows\n",
      "Processing train_data.csv in chunks of 100000...\n",
      "Chunk 1 processed\n",
      "Chunk 2 processed\n",
      "Chunk 3 processed\n",
      "Chunk 4 processed\n",
      "Chunk 5 processed\n",
      "⚠️ TESTING MODE: Stopping after 5 chunks to save time.\n",
      "Concatenating all chunks...\n",
      "Final aggregation to ensure unique customers...\n",
      "Data shape after aggregation: (41444, 187)\n",
      "Merging with Target Labels...\n",
      "Saving to processed_customer_summary.csv...\n",
      "--- SUCCESS! Pipeline finished in 9.76 seconds ---\n",
      "File saved: processed_customer_summary.csv\n",
      "Final Row Count: 41444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 1. Setup Paths\n",
    "TRAIN_PATH = 'train_data.csv'\n",
    "LABEL_PATH = 'train_labels.csv'\n",
    "OUTPUT_PATH = 'processed_customer_summary.csv'\n",
    "\n",
    "def process_data():\n",
    "    start_time = time.time()\n",
    "    print(\"--- Starting Big Data Pipeline ---\")\n",
    "\n",
    "    # 2. Load Labels (Targets)\n",
    "    # We need these to know who actually defaulted\n",
    "    print(\"Loading labels...\")\n",
    "    labels = pd.read_csv(LABEL_PATH)\n",
    "    print(f\"Labels loaded: {len(labels)} rows\")\n",
    "\n",
    "    # 3. Initialize Chunk Processing\n",
    "    chunk_size = 100000 \n",
    "    chunk_list = []\n",
    "    \n",
    "    print(f\"Processing {TRAIN_PATH} in chunks of {chunk_size}...\")\n",
    "\n",
    "    # 4. The Loop\n",
    "    # We use 'numeric_only=True' to automatically skip the date column (S_2) and IDs\n",
    "    with pd.read_csv(TRAIN_PATH, chunksize=chunk_size) as reader:\n",
    "        for i, chunk in enumerate(reader):\n",
    "            \n",
    "            # --- SAFETY BRAKE FOR TESTING ---\n",
    "            # Remove or comment out these 2 lines when you want to run the FULL file!\n",
    "            if i == 5: \n",
    "                print(\"⚠️ TESTING MODE: Stopping after 5 chunks to save time.\")\n",
    "                break \n",
    "            # --------------------------------\n",
    "            \n",
    "            # Group by Customer ID and take the average of all numeric columns\n",
    "            # This turns multiple monthly statements into one 'Average Behavior' row\n",
    "            aggregated_chunk = chunk.groupby('customer_ID').mean(numeric_only=True)\n",
    "            \n",
    "            # Reset index to make customer_ID a normal column again\n",
    "            aggregated_chunk.reset_index(inplace=True)\n",
    "            \n",
    "            chunk_list.append(aggregated_chunk)\n",
    "            print(f\"Chunk {i+1} processed\")\n",
    "\n",
    "    # 5. Combine and Finalize\n",
    "    print(\"Concatenating all chunks...\")\n",
    "    train_df = pd.concat(chunk_list, axis=0)\n",
    "    \n",
    "    # Second Aggregation: \n",
    "    # Because a customer's data might be split across two different chunks,\n",
    "    # we group by customer_ID one last time to ensure exactly 1 row per customer.\n",
    "    print(\"Final aggregation to ensure unique customers...\")\n",
    "    train_df = train_df.groupby('customer_ID').mean(numeric_only=True).reset_index()\n",
    "    \n",
    "    print(f\"Data shape after aggregation: {train_df.shape}\")\n",
    "\n",
    "    # 6. Merge with Labels\n",
    "    print(\"Merging with Target Labels...\")\n",
    "    final_data = train_df.merge(labels, on='customer_ID', how='inner')\n",
    "    \n",
    "    # 7. Save to CSV\n",
    "    print(f\"Saving to {OUTPUT_PATH}...\")\n",
    "    final_data.to_csv(OUTPUT_PATH, index=False)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"--- SUCCESS! Pipeline finished in {elapsed:.2f} seconds ---\")\n",
    "    print(f\"File saved: {OUTPUT_PATH}\")\n",
    "    print(f\"Final Row Count: {len(final_data)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b1039a-2743-443f-82e6-87675fd2db49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>1.005086</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.113215</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.991083</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.120578</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.059876</td>\n",
       "      <td>0.955264</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.247750</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.814543</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID       P_2      D_39  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.933824  0.010704   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.899820  0.215205   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.878454  0.004181   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.598969  0.048862   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.891679  0.004644   \n",
       "\n",
       "        B_1       B_2       R_1       S_3      D_41       B_3  D_42  ...  \\\n",
       "0  0.012007  1.005086  0.004509  0.113215  0.005021  0.006456   NaN  ...   \n",
       "1  0.025654  0.991083  0.006246  0.120578  0.004993  0.005663   NaN  ...   \n",
       "2  0.004386  0.815677  0.006621       NaN  0.006842  0.005493   NaN  ...   \n",
       "3  0.059876  0.955264  0.005665  0.247750  0.005490  0.006423   NaN  ...   \n",
       "4  0.005941  0.814543  0.004180  0.173102  0.005352  0.005088   NaN  ...   \n",
       "\n",
       "   D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144  \\\n",
       "0    NaN    NaN  0.003664  0.005343  0.005178    NaN  0.005066  0.005283   \n",
       "1    NaN    NaN  0.004906  0.006271  0.006007    NaN  0.004824  0.004218   \n",
       "2    NaN    NaN  0.006006  0.004675  0.003607    NaN  0.004288  0.005113   \n",
       "3    NaN    NaN  0.005775  0.005777  0.004181    NaN  0.006742  0.004768   \n",
       "4    NaN    NaN  0.003853  0.004818  0.004818    NaN  0.004852  0.004380   \n",
       "\n",
       "      D_145  target  \n",
       "0  0.005814       0  \n",
       "1  0.004902       0  \n",
       "2  0.004500       0  \n",
       "3  0.005236       0  \n",
       "4  0.004219       0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_customer_summary.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa7106-e941-4833-9be8-c5f406d12753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
