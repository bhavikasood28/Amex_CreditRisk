American Express provided a massive anonymized dataset of more than 16GB containing hundreds of thousands of customer credit-card transactions. The goal was to identify high-risk customers and improve approval decisions, but the dataset was too large for direct analysis and the raw transaction-level structure wasn’t usable for predictive modeling. I was tasked with building an end-to-end credit-risk prediction system that could process extremely large datasets, engineer meaningful customer-level behavioral features, train an accurate and explainable model, and deliver insights through a business-facing dashboard. To tackle this, I engineered a complete data pipeline: I extracted and aggregated millions of records using advanced SQL joins, filters, and window functions, and designed a Python chunking process that loaded and processed the 16GB dataset efficiently in 100k-row batches. Based on this pipeline, I created over 500 customer-level features—including spending trends, delinquency counts, rolling averages, balance metrics, and payment behaviors. I then trained and tuned a Random Forest model and validated its performance using AUC. For explainability, I applied SHAP values to identify the strongest drivers of customer default and to generate transparent, regulator-ready explanations. Finally, I built an interactive Tableau dashboard that allowed business managers to adjust approval thresholds and immediately see the impact on approval rate, expected losses, expected revenue, and net profit. The results were significant: I achieved a 0.94 AUC, well above typical industry benchmarks; reduced processing time from “impossible in Excel” to a fully automated pipeline; delivered a clear explainability framework through SHAP; and provided a practical business tool that enabled leaders to choose the approval cutoff that maximized profit by balancing revenue opportunity with default risk.
